# ============================
# Part 3: Real-time Webcam Lip Reading
# ============================

import os, sys

# Configuration
REPO_DIR = "/content/lipreading"
REALTIME_SCRIPT = f"{REPO_DIR}/realtime_lip_reading.py"

# Add repo to Python path
if REPO_DIR not in sys.path:
    sys.path.insert(0, REPO_DIR)

# Download the real-time script if not exists
if not os.path.exists(REALTIME_SCRIPT):
    print("üì• Downloading real-time lip reading script...")
    
    script_content = '''# ============================
# Part 3: Real-time Webcam Lip Reading
# ============================

import os
import cv2
import time
import torch
import numpy as np
import threading
import queue
from collections import deque
from configparser import ConfigParser
import warnings
warnings.filterwarnings("ignore")

# Import the existing pipeline components
from pipelines.pipeline import InferencePipeline
from pipelines.data.data_module import AVSRDataLoader
from pipelines.detectors.mediapipe.detector import LandmarksDetector
from pipelines.detectors.mediapipe.video_process import VideoProcess
from pipelines.data.transforms import VideoTransform

class RealtimeLipReader:
    def __init__(self, config_path, device="cuda:0", buffer_seconds=4, process_interval=1):
        """
        Real-time lip reading from webcam
        
        Args:
            config_path: Path to model config file
            device: GPU device
            buffer_seconds: Seconds of video to buffer for processing
            process_interval: How often to process (in seconds)
        """
        print("üöÄ Initializing Real-time Lip Reader...")
        
        self.device = device
        self.buffer_seconds = buffer_seconds
        self.process_interval = process_interval
        self.fps = 25  # Target FPS for processing
        self.buffer_size = int(self.fps * buffer_seconds)
        
        # Load model and pipeline
        self.load_model(config_path)
        
        # Initialize video capture
        self.cap = cv2.VideoCapture(0)
        self.cap.set(cv2.CAP_PROP_FPS, 30)  # Webcam FPS
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        # Threading and buffering
        self.frame_buffer = deque(maxlen=self.buffer_size)
        self.frame_timestamps = deque(maxlen=self.buffer_size)
        self.capture_queue = queue.Queue(maxsize=10)
        self.processing_queue = queue.Queue(maxsize=3)
        
        # Control variables
        self.is_recording = False
        self.is_running = True
        self.last_process_time = 0
        self.current_result = "Ready to start... Press SPACE to begin"
        self.processing_status = "Idle"
        
        # Initialize landmarks detector
        self.landmarks_detector = LandmarksDetector()
        
        print("‚úÖ Real-time Lip Reader initialized successfully!")
        print("\\nüéÆ Controls:")
        print("  SPACE: Start/Stop recording")
        print("  ENTER: Force process current buffer")
        print("  ESC: Quit")
        print("  q: Quit")
    
    def load_model(self, config_path):
        """Load the lip reading model and pipeline"""
        print("üì• Loading lip reading model...")
        
        # Read config
        config = ConfigParser()
        config.read(config_path)
        
        # Initialize pipeline (reusing exact same code as infer.py)
        self.pipeline = InferencePipeline(
            config_filename=config_path,
            detector="mediapipe",
            face_track=True,
            device=self.device
        )
        
        # Initialize data processing components
        modality = config.get("input", "modality")
        input_v_fps = config.getfloat("input", "v_fps")
        model_v_fps = config.getfloat("model", "v_fps")
        speed_rate = input_v_fps / model_v_fps
        
        self.dataloader = AVSRDataLoader(
            modality=modality,
            speed_rate=speed_rate,
            detector="mediapipe",
            convert_gray=True
        )
        
        print("‚úÖ Model loaded successfully!")
    
    def capture_frames(self):
        """Capture frames from webcam in separate thread"""
        while self.is_running:
            ret, frame = self.cap.read()
            if ret:
                timestamp = time.time()
                
                if self.is_recording:
                    # Add to buffer for processing
                    self.frame_buffer.append(frame.copy())
                    self.frame_timestamps.append(timestamp)
                
                # Add to display queue
                try:
                    self.capture_queue.put_nowait((frame, timestamp))
                except queue.Full:
                    pass  # Skip if queue is full
            else:
                break
    
    def process_video_segment(self):
        """Process video segments for lip reading in separate thread"""
        while self.is_running:
            try:
                # Wait for processing request
                process_data = self.processing_queue.get(timeout=1.0)
                if process_data is None:
                    break
                
                frames, timestamps = process_data
                self.processing_status = "Processing..."
                
                try:
                    # Process the video segment
                    result = self.process_frames(frames)
                    if result and result.strip():
                        self.current_result = f"üìù {result}"
                        print(f"\\nüó£Ô∏è  Lip Reading Result: {result}")
                    else:
                        self.current_result = "üîç Processing... (no clear speech detected)"
                except Exception as e:
                    print(f"‚ùå Processing error: {e}")
                    self.current_result = f"‚ùå Error: {str(e)[:50]}..."
                
                self.processing_status = "Ready"
                self.processing_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"‚ùå Processing thread error: {e}")
                self.processing_status = "Error"
    
    def process_frames(self, frames):
        """Process a sequence of frames through the lip reading pipeline"""
        if len(frames) < 10:  # Need minimum frames
            return None
        
        # Convert frames to numpy array (T, H, W, C)
        video_array = np.array(frames)
        
        # Extract landmarks for all frames
        landmarks = []
        for frame in frames:
            frame_landmarks = self.landmarks_detector(frame)
            landmarks.append(frame_landmarks)
        
        # Process video through the same pipeline as file-based inference
        try:
            # Use the video processing pipeline
            processed_video = self.pipeline.dataloader.video_process(video_array, landmarks)
            
            if processed_video is None or len(processed_video) == 0:
                return None
            
            # Convert to tensor and apply transforms
            video_tensor = torch.tensor(processed_video)
            transformed_video = self.pipeline.dataloader.video_transform(video_tensor)
            
            # Run inference
            result = self.pipeline.model.infer(transformed_video)
            return result
            
        except Exception as e:
            print(f"‚ùå Frame processing error: {e}")
            return None
    
    def should_process_now(self):
        """Check if we should process the current buffer"""
        current_time = time.time()
        
        # Check if enough time has passed since last processing
        if current_time - self.last_process_time < self.process_interval:
            return False
        
        # Check if we have enough frames
        if len(self.frame_buffer) < self.buffer_size * 0.7:  # At least 70% of buffer
            return False
        
        return True
    
    def trigger_processing(self, force=False):
        """Trigger processing of current buffer"""
        if not self.is_recording or len(self.frame_buffer) == 0:
            return
        
        if not force and not self.should_process_now():
            return
        
        # Copy current buffer for processing
        frames = list(self.frame_buffer)
        timestamps = list(self.frame_timestamps)
        
        # Add to processing queue
        try:
            self.processing_queue.put_nowait((frames, timestamps))
            self.last_process_time = time.time()
        except queue.Full:
            print("‚ö†Ô∏è  Processing queue full, skipping...")
    
    def draw_status_overlay(self, frame):
        """Draw status overlay on frame"""
        # Status indicator circle
        center = (30, 30)
        radius = 15
        
        if self.is_recording:
            color = (0, 255, 0)  # Green
            status = "RECORDING"
        else:
            color = (0, 0, 255)  # Red  
            status = "PAUSED"
        
        cv2.circle(frame, center, radius, color, -1)
        cv2.putText(frame, status, (55, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # Buffer status
        buffer_pct = len(self.frame_buffer) / self.buffer_size * 100
        buffer_text = f"Buffer: {buffer_pct:.0f}%"
        cv2.putText(frame, buffer_text, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # Processing status
        proc_text = f"Status: {self.processing_status}"
        cv2.putText(frame, proc_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # Current result (truncated for display)
        result_display = self.current_result[:60] + "..." if len(self.current_result) > 60 else self.current_result
        cv2.putText(frame, result_display, (10, frame.shape[0] - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        
        # Controls help
        help_text = "SPACE: Start/Stop | ENTER: Process | ESC/q: Quit"
        cv2.putText(frame, help_text, (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)
        
        return frame
    
    def run(self):
        """Main loop for real-time lip reading"""
        print("\\nüé¨ Starting real-time lip reading...")
        print("üìπ Webcam feed should appear. Press SPACE to start recording.")
        
        # Start capture and processing threads
        capture_thread = threading.Thread(target=self.capture_frames, daemon=True)
        processing_thread = threading.Thread(target=self.process_video_segment, daemon=True)
        
        capture_thread.start()
        processing_thread.start()
        
        try:
            while self.is_running:
                # Get frame for display
                try:
                    frame, timestamp = self.capture_queue.get(timeout=0.1)
                except queue.Empty:
                    continue
                
                # Draw status overlay
                display_frame = self.draw_status_overlay(frame)
                
                # Show frame
                cv2.imshow('Real-time Lip Reading', display_frame)
                
                # Handle keyboard input
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord(' '):  # Space - toggle recording
                    self.is_recording = not self.is_recording
                    if self.is_recording:
                        print("üü¢ Recording started!")
                        self.current_result = "Recording... Speak to the camera"
                        self.frame_buffer.clear()
                        self.frame_timestamps.clear()
                    else:
                        print("üî¥ Recording paused!")
                        self.current_result = "Recording paused. Press SPACE to resume"
                
                elif key == ord('\\r') or key == ord('\\n'):  # Enter - force process
                    print("‚ö° Force processing current buffer...")
                    self.trigger_processing(force=True)
                
                elif key == 27 or key == ord('q'):  # ESC or 'q' - quit
                    print("üëã Quitting...")
                    break
                
                # Auto-trigger processing for overlapping segments
                if self.is_recording:
                    self.trigger_processing()
        
        except KeyboardInterrupt:
            print("\\nüëã Interrupted by user")
        
        finally:
            self.cleanup()
    
    def cleanup(self):
        """Clean up resources"""
        print("üßπ Cleaning up...")
        self.is_running = False
        
        # Signal processing thread to stop
        try:
            self.processing_queue.put_nowait(None)
        except queue.Full:
            pass
        
        # Release webcam
        if self.cap:
            self.cap.release()
        
        cv2.destroyAllWindows()
        print("‚úÖ Cleanup completed!")


def main():
    """Main function to run real-time lip reading"""
    # Configuration
    REPO_DIR = "/content/lipreading"
    CONFIG_PATH = f"{REPO_DIR}/configs/LRS3_V_WER19.1.ini"
    DEVICE = "cuda:0" if torch.cuda.is_available() else "cpu"
    
    # Validate setup
    if not os.path.exists(CONFIG_PATH):
        print(f"‚ùå Config file not found: {CONFIG_PATH}")
        print("Please run Part 1 first to download models!")
        return
    
    # Check model files
    model_files = [
        f"{REPO_DIR}/benchmarks/LRS3/models/LRS3_V_WER19.1/model.pth",
        f"{REPO_DIR}/benchmarks/LRS3/models/LRS3_V_WER19.1/model.json",
        f"{REPO_DIR}/benchmarks/LRS3/language_models/lm_en_subword/model.pth",
        f"{REPO_DIR}/benchmarks/LRS3/language_models/lm_en_subword/model.json",
    ]
    
    missing_files = [f for f in model_files if not os.path.exists(f)]
    if missing_files:
        print("‚ùå Missing model files:")
        for f in missing_files:
            print(f"  - {f}")
        print("Please run Part 1 first to download models!")
        return
    
    print(f"üéØ Using device: {DEVICE}")
    print(f"üìã Config: {CONFIG_PATH}")
    
    # Initialize and run real-time lip reader
    try:
        lip_reader = RealtimeLipReader(
            config_path=CONFIG_PATH,
            device=DEVICE,
            buffer_seconds=4,      # 4 second buffer for better accuracy
            process_interval=1     # Process every 1 second for overlapping segments
        )
        lip_reader.run()
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()'''
    
    with open(REALTIME_SCRIPT, 'w') as f:
        f.write(script_content)
    print("‚úÖ Real-time script created!")

# Validate environment
print("üîç Checking environment...")

# Check if models are downloaded
CONFIG_PATH = f"{REPO_DIR}/configs/LRS3_V_WER19.1.ini"
model_files = [
    f"{REPO_DIR}/benchmarks/LRS3/models/LRS3_V_WER19.1/model.pth",
    f"{REPO_DIR}/benchmarks/LRS3/models/LRS3_V_WER19.1/model.json",
    f"{REPO_DIR}/benchmarks/LRS3/language_models/lm_en_subword/model.pth",
    f"{REPO_DIR}/benchmarks/LRS3/language_models/lm_en_subword/model.json",
]

missing_files = [f for f in model_files if not os.path.exists(f)]
if missing_files:
    print("‚ùå Missing model files:")
    for f in missing_files:
        print(f"  - {f}")
    print("\nüö® Please run Part 1 first to download models!")
else:
    print("‚úÖ All model files found!")
    print("‚úÖ Environment ready!")
    
    # Import and run
    print("\nüöÄ Starting Real-time Lip Reading...")
    print("üìπ Your webcam should activate and a window will appear.")
    print("üéÆ Use the keyboard controls to start/stop recording.")
    print("\n" + "="*60)
    
    # Change to repo directory and run
    os.chdir(REPO_DIR)
    exec(open(REALTIME_SCRIPT).read())
