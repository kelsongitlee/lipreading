# ============================
# Part 2: Inference (Analyze video)
# ============================

import os, subprocess

# Inputs you can change:
# Option 1: Use downloaded video samples (change filename only)
VIDEO_FILENAME = "video_muted1.mp4"     # Available: video_muted1.mp4, or upload your own
VIDEO_PATH = f"/content/lipreading/video_samples/{VIDEO_FILENAME}"

# Option 2: Or specify custom path directly
# VIDEO_PATH = "/content/your_custom_video.mp4"

GPU_IDX = 0                             # set -1 for CPU
USE_MEDIAPIPE = True                    # True uses mediapipe; no ibug needed

REPO_DIR = "/content/lipreading"
CONFIG_PATH = f"{REPO_DIR}/configs/LRS3_V_WER19.1.ini"

def run(cmd, desc=None, check=True):
  print("\n" + "="*60)
  print(desc or cmd)
  print("="*60)
  r = subprocess.run(cmd, shell=True, text=True, capture_output=True)
  if r.stdout.strip(): print(r.stdout)
  if r.returncode != 0:
    if r.stderr.strip(): print(r.stderr)
    if check: raise RuntimeError(f"Command failed: {cmd}")
  return r

# Basic checks
assert os.path.isdir(REPO_DIR), "Repo folder not found. Run Part 1 first."

# Show available video samples
video_samples_dir = f"{REPO_DIR}/video_samples"
if os.path.exists(video_samples_dir):
  available_videos = [f for f in os.listdir(video_samples_dir) if f.endswith(('.mp4', '.avi', '.mov'))]
  if available_videos:
    print(f"üìπ Available video samples: {', '.join(available_videos)}")
    print(f"üí° To test different videos, change VIDEO_FILENAME to: {available_videos}")
  else:
    print("üìÅ Video samples folder exists but no videos found")

assert os.path.isfile(VIDEO_PATH), f"Video not found: {VIDEO_PATH}. Check VIDEO_FILENAME or upload video to {video_samples_dir}"
for p in (
  f"{REPO_DIR}/benchmarks/LRS3/models/LRS3_V_WER19.1/model.pth",
  f"{REPO_DIR}/benchmarks/LRS3/models/LRS3_V_WER19.1/model.json",
  f"{REPO_DIR}/benchmarks/LRS3/language_models/lm_en_subword/model.pth",
  f"{REPO_DIR}/benchmarks/LRS3/language_models/lm_en_subword/model.json",
):
  assert os.path.isfile(p), f"Missing model file: {p}. Please rerun Part 1 to download models."

detector = "mediapipe" if USE_MEDIAPIPE else "retinaface"
cmd = f'cd {REPO_DIR} && python infer.py config_filename={CONFIG_PATH} data_filename="{VIDEO_PATH}" detector={detector} gpu_idx={GPU_IDX}'
run(cmd, f"Running inference on: {VIDEO_PATH} (detector={detector}, gpu_idx={GPU_IDX})")

print("\n‚úÖ Inference finished. Look above for a line like:  hyp: <transcription>")